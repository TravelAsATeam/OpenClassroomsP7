{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ce notebook a pour objectif de rechercher le meilleur modèle de prédiction pour des données déjà traitées. Un des points importants qu'ilm conviendra de résoudre est le déséquilibre entre les classes. Pöur résoudre ce problème, plusieurs possibilités s'offrent à nous. Il conviendra de tester différentes méthodes mais également de tester des combinaisons de méthodes.\n",
    "\n",
    " Méthodes de gestion du déséquilibre de classe et un exemple :\n",
    "     - choix de métriques adaptées (Score Fbeta)\n",
    "     - pondération des erreurs en fonction du déséquilibre des classes (class_weight)\n",
    "     - choix d'algorithmes adaptés (Random forest)\n",
    "     - Sous ou sur échantillonnage (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix des métriques adaptées :\n",
    "Dans le cas de classes déséquilibrées, il est fréquent que toutes les erreurs ne se valent pas. Ici, les évènements positifs (défaut de paiement) son bien plus rares que les évènements négatifs. D'un point de vue purement rentable, il vaut mieux faire l'erreur de ne pas octroyer de prêt à un bon payeur que d'en octroyer un à un mauvais payeur. Avoir des faux positifs est donc plus désirable que d'avoir des faux négatifs.\n",
    "\n",
    "La question est plus complexe s'il on intègre des notions d'éthique, puisque refuser un prêt à un bon payeur à des conséquences négatives, ainsi il faudrait discuter des problématiques éthiques à refuser l'ocrtoi d'un prêt à un bon payeur ou en octroyer un à un mauvais payeur. Il faudrait ensuite calculer un coefficient de non-désirabilité qui permettrait d'évaluer quelle est l'importance des faux positifs par rapport aux faux négatifs.\n",
    "\n",
    "C'est une question complexe qui demande une réflexion éthique et économique.\n",
    "\n",
    "Pour l'exercice, nous fixerons le rapport de non désirabilité à cette règle : un faux négatif a un impact négatif 10 fois plus important qu'un faux positif.\n",
    "\n",
    "A partir de cette règle on peut déterminer le paramètre beta d'un F-beta score qui permettra d'adapter la métrique d'évaluation au problème de déséquilibre des classes et de la différence d'impact des erreurs. Dans ce cas, c'est le recall qui aura plus d'importance que la precision. beta = racine_carrée(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pondération  des erreurs :\n",
    "La méthode de pondération des erreurs en fonction du déséquilibre des classes consiste à considérer les erreurs effectuées sur la classe mineure comme plus importantes que celles commises sur la classe majeure. Le ratio qui relie ces importances peut correspondre au ratio du nombre d'observations entre la classe mineure et la classe majeure.\n",
    "\n",
    "Il me semble que cette méthode est redondante avec le choix d'un F-beta score bien que le F-beta soit conçu pour refléter la gravité d'une erreur plutôt qu'une autre alors que le class_weight est conçu pour s'adapter au déséquilibre dans le nombre d'observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratégie \n",
    "\n",
    "En utilisant une métrique F-beta score pondérée pour donner plus d'importance aux faux négatifs (qui sont des erreurs plus importantes), on va tester les méthodes de sous-échantillonnage aléatoire et sur-échantillonnage type SMOTE en les combinant avec différents algorithmes tels que : la regression logistique, la random forest et kNN. Il y a d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in g:\\softwares\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in g:\\softwares\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in g:\\softwares\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.24 in g:\\softwares\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in g:\\softwares\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in g:\\softwares\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du fichier de données pré-traitées\n",
    "default_dir = \"G:/OCDataScientist/Projet7\"\n",
    "data = pd.read_csv(os.path.join(default_dir,'data_train.csv'))\n",
    "\n",
    "# Création d'un imputer pour remplacer les valeurs manquantes\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# Remplacement des valeurs manquantes\n",
    "temp_DF = pd.DataFrame(imputer.fit_transform(data))\n",
    "# Réintégration des colonnes et index\n",
    "temp_DF.columns = data.columns\n",
    "temp_DF.index = data.index\n",
    "data = temp_DF\n",
    "\n",
    "# Création d'un scaler 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(data)\n",
    "\n",
    "# Normalisation des variables\n",
    "temp_DF = pd.DataFrame(scaler.transform(data))\n",
    "# Réintégration des colonnes et index\n",
    "temp_DF.columns = data.columns\n",
    "temp_DF.index = data.index\n",
    "data = temp_DF\n",
    "\n",
    "# Sauvegarde du DataFrame des données prêtes à être modélisées\n",
    "#Export des fichiers de données traités\n",
    "output_dir = \"G:/OCDataScientist/Projet7\"\n",
    "data.to_csv(os.path.join(output_dir,'data_train_std.csv'), index=False)\n",
    "\n",
    "\n",
    "# Décomposition train/test\n",
    "y = data['TARGET'].values\n",
    "X = data.drop(columns = ['TARGET']).values\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3,\n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition originale: Counter({0.0: 197772, 1.0: 17485})\n",
      "Répartition après sous-échantillonnage Counter({0.0: 17485, 1.0: 17485})\n"
     ]
    }
   ],
   "source": [
    "# Sous-échantillonnage\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Vérification\n",
    "from collections import Counter\n",
    "print('Répartition originale:', Counter(y_train))\n",
    "print('Répartition après sous-échantillonnage', Counter(y_train_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition originale: Counter({0.0: 197772, 1.0: 17485})\n",
      "Répartition après sur-échantillonnage Counter({0.0: 197772, 1.0: 197772})\n"
     ]
    }
   ],
   "source": [
    "# Sur-échantillonnage SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Vérification\n",
    "from collections import Counter\n",
    "print('Répartition originale:', Counter(y_train))\n",
    "print('Répartition après sur-échantillonnage', Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une métrique adaptée Fbeta score pour le GridSearchCV\n",
    "from sklearn import metrics\n",
    "target = metrics.make_scorer(metrics.fbeta_score, beta=3.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 0.07\n",
      "Testing Time: 285.29\n",
      "Accuracy: 0.915\n",
      "Fbeta: 0.018\n",
      "[[84286   628]\n",
      " [ 7218   122]]\n",
      "Training Time: 0.01\n",
      "Testing Time: 47.99\n",
      "Accuracy: 0.550\n",
      "Fbeta: 0.412\n",
      "[[46388 38526]\n",
      " [ 2987  4353]]\n",
      "Training Time: 0.16\n",
      "Testing Time: 553.62\n",
      "Accuracy: 0.625\n",
      "Fbeta: 0.354\n",
      "[[54213 30701]\n",
      " [ 3879  3461]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Entrainement sur le jeu de données déséquilibré\n",
    "knn_imb = KNeighborsClassifier()\n",
    "start = time()\n",
    "knn_imb.fit(X_train, y_train)\n",
    "end = time()\n",
    "time_knn_imb_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_knn_imb_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_knn_imb_pred = knn_imb.predict(X_test)\n",
    "end = time()\n",
    "time_knn_imb_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_knn_imb_pred))\n",
    "# Métriques\n",
    "acc_knn_imb = metrics.accuracy_score(y_test, y_knn_imb_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_knn_imb))\n",
    "fbeta_knn_imb = metrics.fbeta_score(y_test, y_knn_imb_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_knn_imb))\n",
    "confusion_knn_imb = metrics.confusion_matrix(y_test, y_knn_imb_pred)\n",
    "print(confusion_knn_imb)\n",
    "\n",
    "# Entrainement sur le jeu de données sous échantillonné\n",
    "knn_rus = KNeighborsClassifier()\n",
    "start = time()\n",
    "knn_rus.fit(X_train_rus, y_train_rus)\n",
    "end = time()\n",
    "time_knn_rus_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_knn_rus_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_knn_rus_pred = knn_rus.predict(X_test)\n",
    "end = time()\n",
    "time_knn_rus_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_knn_rus_pred))\n",
    "# Métriques\n",
    "acc_knn_rus = metrics.accuracy_score(y_test, y_knn_rus_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_knn_rus))\n",
    "fbeta_knn_rus = metrics.fbeta_score(y_test, y_knn_rus_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_knn_rus))\n",
    "confusion_knn_rus = metrics.confusion_matrix(y_test, y_knn_rus_pred)\n",
    "print(confusion_knn_rus)\n",
    "\n",
    "# Entrainement sur le jeu de données sur-échantillonné\n",
    "knn_smote = KNeighborsClassifier()\n",
    "start = time()\n",
    "knn_smote.fit(X_train_smote, y_train_smote)\n",
    "end = time()\n",
    "time_knn_smote_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_knn_smote_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_knn_smote_pred = knn_smote.predict(X_test)\n",
    "end = time()\n",
    "time_knn_smote_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_knn_smote_pred))\n",
    "# Métriques\n",
    "acc_knn_smote = metrics.accuracy_score(y_test, y_knn_smote_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_knn_smote))\n",
    "fbeta_knn_smote = metrics.fbeta_score(y_test, y_knn_smote_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_knn_smote))\n",
    "confusion_knn_smote = metrics.confusion_matrix(y_test, y_knn_smote_pred)\n",
    "print(confusion_knn_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le jeu de données déséquilibré, on retrouve la précision la plus élevée mais on remarque qu'il ne parvient à détecter seulement 122 TP ce qui est très faible. Le Fbeta résultant qui met l'accent sur les TP est donc très bas. Ici le problème du déséquilibre de classes est flagrant.\n",
    "\n",
    "Sur le jeu sous échantillonné, la précision est la plus faible, il repère en effet beaucoup de FP, cependant c'est sur ce jeu là que l'on trouve le plus de TP, il obtient donc le Fbeta le plus élevé.\n",
    "\n",
    "Sur le jeu sur-échantillonné, on obtient des performances plus faibles sur le nombre de TP, il échoue à détecter plus de la moitié des positifs.\n",
    "\n",
    "Globalement, si le jeu sous-échantillonné s'en sort mieux (en prenant comme objectif Fbeta avec beta=3.16), le modèle KNN présente des performances faibles, il repère au mieux 59% des positifs avec un taux de FP de presque 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la suite de la recherche du meilleur algorithme et pour optimiser la recherche des hyperparamètres, il serait intéressant de réduire la taille de l'échantillon et s'il faut réduire l'échantillon pour accélérer cette phase, alors autant en profiter pour le rééquilibrer. La recherche de l'algorithme et des hyper paramèrtres optimaux se fera donc avec le jeu de données rééquilibré par échantillonnage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.67731463        nan 0.67733952 0.67721087\n",
      " 0.67731806 0.67743961 0.67726803 0.67726803        nan        nan\n",
      "        nan        nan 0.67670997]\n",
      "  warnings.warn(\n",
      "G:\\Softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1476: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Time: 453.56\n",
      "{'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "Résultats de la validation croisée :\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l1', 'random_state': 0, 'solver': 'newton-cg'}\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l1', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.009) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l1', 'random_state': 0, 'solver': 'liblinear'}\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l1', 'random_state': 0, 'solver': 'sag'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.009) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l1', 'random_state': 0, 'solver': 'saga'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.010) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 0, 'solver': 'newton-cg'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.010) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.010) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.010) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 0, 'solver': 'sag'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.010) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 0, 'solver': 'saga'}\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'elasticnet', 'random_state': 0, 'solver': 'newton-cg'}\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'elasticnet', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'elasticnet', 'random_state': 0, 'solver': 'liblinear'}\n",
      "make_scorer(fbeta_score, beta=3.16) = nan (+/-nan) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'elasticnet', 'random_state': 0, 'solver': 'sag'}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.677 (+/-0.009) for {'class_weight': None, 'l1_ratio': 0.5, 'max_iter': 1000, 'penalty': 'elasticnet', 'random_state': 0, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# Regression logistique avec GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "paramGrid = {'penalty': ['l1','l2','elasticnet'], 'random_state' : [0],\n",
    "             'class_weight' : [None], \n",
    "             'solver' : ['newton-cg', 'lbfgs', 'liblinear','sag','saga'], 'max_iter' :[1000], 'l1_ratio' : [0.5] }\n",
    "\n",
    "# Entrainement sur le jeu de données sous échantillonné\n",
    "start = time()\n",
    "reg_rus = reg = model_selection.GridSearchCV(LogisticRegression(), paramGrid, cv=5, scoring=target)\n",
    "reg_rus.fit(X_train_rus, y_train_rus)\n",
    "end = time()\n",
    "time_reg_grid = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_reg_grid))\n",
    "\n",
    "print(reg_rus.best_params_)\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(reg_rus.cv_results_['mean_test_score'],\n",
    "                             reg_rus.cv_results_['std_test_score'],  reg_rus.cv_results_['params']):\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(target,mean,std,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur solver par regression logistique semble être le liblinear avec une pénalité l2. Nous allons maintenant le tester avec les 3 jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 13.45\n",
      "Testing Time: 0.03\n",
      "Accuracy: 0.920\n",
      "Fbeta: 0.012\n",
      "[[84821    93]\n",
      " [ 7262    78]]\n",
      "Training Time: 1.98\n",
      "Testing Time: 0.03\n",
      "Accuracy: 0.685\n",
      "Fbeta: 0.523\n",
      "[[58212 26702]\n",
      " [ 2344  4996]]\n",
      "Training Time: 36.35\n",
      "Testing Time: 0.03\n",
      "Accuracy: 0.698\n",
      "Fbeta: 0.507\n",
      "[[59668 25246]\n",
      " [ 2574  4766]]\n"
     ]
    }
   ],
   "source": [
    "# Regression Logistique\n",
    "\n",
    "# Entrainement sur le jeu de données déséquilibré\n",
    "reg_imb = LogisticRegression(penalty = 'l2', solver = 'liblinear', random_state = 0, max_iter = 1000)\n",
    "start = time()\n",
    "reg_imb.fit(X_train, y_train)\n",
    "end = time()\n",
    "time_reg_imb_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_reg_imb_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_reg_imb_pred = reg_imb.predict(X_test)\n",
    "end = time()\n",
    "time_reg_imb_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_reg_imb_pred))\n",
    "# Métriques\n",
    "acc_reg_imb = metrics.accuracy_score(y_test, y_reg_imb_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_reg_imb))\n",
    "fbeta_reg_imb = metrics.fbeta_score(y_test, y_reg_imb_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_reg_imb))\n",
    "confusion_reg_imb = metrics.confusion_matrix(y_test, y_reg_imb_pred)\n",
    "print(confusion_reg_imb)\n",
    "\n",
    "# Entrainement sur le jeu de données sous échantillonné\n",
    "reg_rus = LogisticRegression(penalty = 'l2', solver = 'liblinear', random_state = 0, max_iter = 1000)\n",
    "start = time()\n",
    "reg_rus.fit(X_train_rus, y_train_rus)\n",
    "end = time()\n",
    "time_reg_rus_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_reg_rus_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_reg_rus_pred = reg_rus.predict(X_test)\n",
    "end = time()\n",
    "time_reg_rus_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_reg_rus_pred))\n",
    "# Métriques\n",
    "acc_reg_rus = metrics.accuracy_score(y_test, y_reg_rus_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_reg_rus))\n",
    "fbeta_reg_rus = metrics.fbeta_score(y_test, y_reg_rus_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_reg_rus))\n",
    "confusion_reg_rus = metrics.confusion_matrix(y_test, y_reg_rus_pred)\n",
    "print(confusion_reg_rus)\n",
    "\n",
    "# Entrainement sur le jeu de données sur-échantillonné\n",
    "reg_smote = LogisticRegression(penalty = 'l2', solver = 'liblinear', random_state = 0, max_iter = 1000)\n",
    "start = time()\n",
    "reg_smote.fit(X_train_smote, y_train_smote)\n",
    "end = time()\n",
    "time_reg_smote_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_reg_smote_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_reg_smote_pred = reg_smote.predict(X_test)\n",
    "end = time()\n",
    "time_reg_smote_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_reg_smote_pred))\n",
    "# Métriques\n",
    "acc_reg_smote = metrics.accuracy_score(y_test, y_reg_smote_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_reg_smote))\n",
    "fbeta_reg_smote = metrics.fbeta_score(y_test, y_reg_smote_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_reg_smote))\n",
    "confusion_reg_smote = metrics.confusion_matrix(y_test, y_reg_smote_pred)\n",
    "print(confusion_reg_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La comparaison des jeux de données est assez similaire avec celle que nous avons fait lors du kNN, le jeu déséquilibré apporte une précision très élevée mais ne parvient pas à détecter les TP, le jeu sous-échantillonné présente les meilleurs résultats sur la métrique principale (Fbeta score).\n",
    "\n",
    "Si la regression logistique présente de meilleurs résultats que le kNN, notamment sur une bonne détection des TP, elle échoue en détectant près d'un tiers de faux positifs. Au vu de l'utilisation finale du modèle, ces résultats ne me semblent pas suffisants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Time: 5289.83\n",
      "{'learning_rate': 0.12, 'loss': 'exponential', 'n_estimators': 250, 'random_state': 0}\n",
      "Résultats de la validation croisée :\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.693 (+/-0.009) for {'learning_rate': 0.12, 'loss': 'exponential', 'n_estimators': 250, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.692 (+/-0.007) for {'learning_rate': 0.12, 'loss': 'exponential', 'n_estimators': 300, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.691 (+/-0.007) for {'learning_rate': 0.12, 'loss': 'exponential', 'n_estimators': 400, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.691 (+/-0.007) for {'learning_rate': 0.15, 'loss': 'exponential', 'n_estimators': 250, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.690 (+/-0.004) for {'learning_rate': 0.15, 'loss': 'exponential', 'n_estimators': 300, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.692 (+/-0.007) for {'learning_rate': 0.15, 'loss': 'exponential', 'n_estimators': 400, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.690 (+/-0.006) for {'learning_rate': 0.25, 'loss': 'exponential', 'n_estimators': 250, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.688 (+/-0.004) for {'learning_rate': 0.25, 'loss': 'exponential', 'n_estimators': 300, 'random_state': 0}\n",
      "make_scorer(fbeta_score, beta=3.16) = 0.688 (+/-0.004) for {'learning_rate': 0.25, 'loss': 'exponential', 'n_estimators': 400, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "# Random forest avec GridSearch CV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Grilles dans l'ordre de recherche\n",
    "paramGrid1 = {'loss' : ['deviance', 'exponential'],\n",
    "             'max_depth': [3,4,5], 'learning_rate':[0.05,0.1,0.02] ,  'n_estimators':[50,100,200], \n",
    "             'random_state':[0]}\n",
    "paramGrid2 = {'loss' : ['exponential'], 'learning_rate':[0.08,0.1,0.12] ,  'n_estimators':[150,200,250], \n",
    "             'random_state':[0]}\n",
    "paramGrid3 = {'loss' : ['exponential'], 'learning_rate': [0.12, 0.15, 0.25] ,  'n_estimators':[250,300,400], \n",
    "             'random_state':[0]}\n",
    "\n",
    "# Entrainement sur le jeu de données sous echantillonné\n",
    "start = time()\n",
    "rf_rus = model_selection.GridSearchCV(GradientBoostingClassifier(), paramGrid3, cv=5, scoring=target)\n",
    "rf_rus.fit(X_train_rus, y_train_rus)\n",
    "end = time()\n",
    "time_rf_grid = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_rf_grid))\n",
    "\n",
    "print(rf_rus.best_params_)\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(rf_rus.cv_results_['mean_test_score'], \n",
    "                             rf_rus.cv_results_['std_test_score'], rf_rus.cv_results_['params']):\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(target,mean,std,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En première approche, on a trouvé les meilleurs paramètres tels que : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 200, 'random_state': 0}\n",
    "\n",
    "En deuxième approche, {'learning_rate': 0.12, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 250, 'random_state': 0}\n",
    "\n",
    "En troisième approche, {'learning_rate': 0.12, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 250, 'random_state': 0} \n",
    "\n",
    "Les mêmes paramètres qu'en deuxième approche.\n",
    "\n",
    "Nous allons maintenant tester ces paramètres avec les 3 jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 1194.85\n",
      "Testing Time: 0.96\n",
      "Accuracy: 0.921\n",
      "Fbeta: 0.025\n",
      "[[84765   149]\n",
      " [ 7174   166]]\n",
      "Training Time: 150.19\n",
      "Testing Time: 0.83\n",
      "Accuracy: 0.694\n",
      "Fbeta: 0.534\n",
      "[[58923 25991]\n",
      " [ 2266  5074]]\n",
      "Training Time: 2730.11\n",
      "Testing Time: 0.86\n",
      "Accuracy: 0.920\n",
      "Fbeta: 0.035\n",
      "[[84640   274]\n",
      " [ 7104   236]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest avec Gradient Boosting\n",
    "\n",
    "# Entrainement sur le jeu de données déséquilibré\n",
    "rf_imb = GradientBoostingClassifier(learning_rate = 0.12, loss = 'exponential', max_depth = 4, \n",
    "                                    n_estimators = 250, random_state = 0)\n",
    "start = time()\n",
    "rf_imb.fit(X_train, y_train)\n",
    "end = time()\n",
    "time_rf_imb_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_rf_imb_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_rf_imb_pred = rf_imb.predict(X_test)\n",
    "end = time()\n",
    "time_rf_imb_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_rf_imb_pred))\n",
    "# Métriques\n",
    "acc_rf_imb = metrics.accuracy_score(y_test, y_rf_imb_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_rf_imb))\n",
    "fbeta_rf_imb = metrics.fbeta_score(y_test, y_rf_imb_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_rf_imb))\n",
    "confusion_rf_imb = metrics.confusion_matrix(y_test, y_rf_imb_pred)\n",
    "print(confusion_rf_imb)\n",
    "\n",
    "# Entrainement sur le jeu de données sous échantillonné\n",
    "rf_rus = GradientBoostingClassifier(learning_rate = 0.12, loss = 'exponential', max_depth = 4, \n",
    "                                    n_estimators = 250, random_state = 0)\n",
    "start = time()\n",
    "rf_rus.fit(X_train_rus, y_train_rus)\n",
    "end = time()\n",
    "time_rf_rus_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_rf_rus_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_rf_rus_pred = rf_rus.predict(X_test)\n",
    "end = time()\n",
    "time_rf_rus_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_rf_rus_pred))\n",
    "# Métriques\n",
    "acc_rf_rus = metrics.accuracy_score(y_test, y_rf_rus_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_rf_rus))\n",
    "fbeta_rf_rus = metrics.fbeta_score(y_test, y_rf_rus_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_rf_rus))\n",
    "confusion_rf_rus = metrics.confusion_matrix(y_test, y_rf_rus_pred)\n",
    "print(confusion_rf_rus)\n",
    "\n",
    "# Entrainement sur le jeu de données sur-échantillonné\n",
    "rf_smote = GradientBoostingClassifier(learning_rate = 0.12, loss = 'exponential', max_depth = 4, \n",
    "                                    n_estimators = 250, random_state = 0)\n",
    "start = time()\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "end = time()\n",
    "time_rf_smote_train = end - start\n",
    "print(\"Training Time: {:.2f}\".format(time_rf_smote_train))\n",
    "# Prédiction\n",
    "start = time()\n",
    "y_rf_smote_pred = rf_smote.predict(X_test)\n",
    "end = time()\n",
    "time_rf_smote_pred = end - start\n",
    "print(\"Testing Time: {:.2f}\".format(time_rf_smote_pred))\n",
    "# Métriques\n",
    "acc_rf_smote = metrics.accuracy_score(y_test, y_rf_smote_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_rf_smote))\n",
    "fbeta_rf_smote = metrics.fbeta_score(y_test, y_rf_smote_pred, beta=3.16)\n",
    "print(\"Fbeta: {:.3f}\".format(fbeta_rf_smote))\n",
    "confusion_rf_smote = metrics.confusion_matrix(y_test, y_rf_smote_pred)\n",
    "print(confusion_rf_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le modèle de forêt aléatoire avec boost par gradient, on obtient toujours un meilleur résultat avec la méthode de sous-échantillonnage, malgré la perte d'information que cette dernière induit. Avec un score de 0.534, il est même légèrement supérieur à la méthode de regression logistique, malgré la perte d'information que cette dernière induit.\n",
    "Si l'on se réfère à la matrice de confusion, on a 27% de FP ce qui est un point négatif non négligeable mais on réussi à repérer 69% de TP ce qui est plutôt élevé considérant que ce n'est pas un problème aisé.\n",
    "Pour ces raisons, c'est ce modèle que l'on utilisera par la suite pour l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_rf.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistance du modèle\n",
    "import joblib\n",
    "joblib.dump(rf_rus, 'model_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
